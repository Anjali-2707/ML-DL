{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbd46d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "409ce483",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap =cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e5e075d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " array([[[78, 56, 44],\n",
       "         [77, 56, 48],\n",
       "         [72, 54, 51],\n",
       "         ...,\n",
       "         [47, 45, 42],\n",
       "         [49, 42, 43],\n",
       "         [50, 42, 43]],\n",
       " \n",
       "        [[73, 55, 41],\n",
       "         [73, 57, 48],\n",
       "         [69, 56, 52],\n",
       "         ...,\n",
       "         [46, 45, 45],\n",
       "         [46, 44, 44],\n",
       "         [47, 44, 44]],\n",
       " \n",
       "        [[67, 49, 47],\n",
       "         [66, 51, 48],\n",
       "         [64, 51, 49],\n",
       "         ...,\n",
       "         [41, 41, 41],\n",
       "         [40, 40, 40],\n",
       "         [40, 40, 40]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[37, 34, 58],\n",
       "         [35, 35, 58],\n",
       "         [31, 33, 55],\n",
       "         ...,\n",
       "         [29, 21, 28],\n",
       "         [30, 23, 22],\n",
       "         [29, 22, 20]],\n",
       " \n",
       "        [[36, 35, 41],\n",
       "         [33, 34, 40],\n",
       "         [30, 33, 39],\n",
       "         ...,\n",
       "         [36, 23, 32],\n",
       "         [36, 22, 23],\n",
       "         [36, 22, 23]],\n",
       " \n",
       "        [[42, 36, 41],\n",
       "         [38, 35, 37],\n",
       "         [36, 36, 36],\n",
       "         ...,\n",
       "         [27, 26, 35],\n",
       "         [30, 25, 26],\n",
       "         [28, 23, 22]]], dtype=uint8))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0662b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret,photo =cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0a04eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03160bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<CascadeClassifier 00000276D3CC2150>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97e36008",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces=model.detectMultiScale(photo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84e94478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[130, 245,  56,  56],\n",
       "       [ 94,  75, 144, 144],\n",
       "       [234,  80, 183, 183]], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faces# 1 array means only 1 face is detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d45e3cde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(faces)#no. of faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b03cb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = faces [0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "716e6225",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = faces[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d947a031",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = x1 + faces[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "474b4492",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = y1 + faces[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc998b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aphoto = cv2.rectangle(photo,(x1,y1),(x2,y2),(0,255,0),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23331510",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"hi\",aphoto)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "edbe321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
